import pandas as pd

def safe_convert_loss_qty(df, col_name='LOSS_QTY'):
    """
    LOSS_QTY ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
    - ë¬¸ìì—´, ê³µë°±, None, '-', '?' ë“± ì²˜ë¦¬
    """
    if col_name not in df.columns:
        raise KeyError(f"ì»¬ëŸ¼ ì—†ìŒ: {col_name}")

    def convert(x):
        try:
            if pd.isna(x):
                return 0
            x_str = str(x).strip()
            if x_str in ['', '-', '.', 'None', 'NULL', 'N/A', '?']:
                return 0
            return int(float(x_str))  # float â†’ int (ì†Œìˆ˜ì  ë²„ë¦¼)
        except:
            return 0  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ 0 ì²˜ë¦¬

    df[col_name] = df[col_name].apply(convert).astype('int64')
    return df


def analyze_flatness(df_lot):
    """
    FLATNESS ë¶ˆëŸ‰ì— ëŒ€í•´ AFT_BAD_RSN_CD ê¸°ì¤€ ìƒìœ„ 3ê°œ ì½”ë“œ ë¶„ì„
    ì¡°ê±´: LOSS_QTY >= 30, ë“±ê¸‰ ì¬ë¶„ë¥˜ ì ìš©
    ì…ë ¥: df_lot (DATA_LOT_3210_wafering_300 ê²°ê³¼)
    """
    # 1. FLATNESS ë°ì´í„° í•„í„°ë§
    df = df_lot[df_lot['REJ_GROUP'] == 'FLATNESS'].copy()
    
    # ë°ì´í„° ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
    if df.empty:
        return ["[FLATNESS ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    # 2. AFT_BAD_RSN_CDë³„ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 3ê°œ
    code_summary = (
        df.groupby('AFT_BAD_RSN_CD')['LOSS_QTY']
        .sum()
        .sort_values(ascending=False)
        .head(3)
    )

    if code_summary.empty:
        return ["[FLATNESS ë¶„ì„] ìƒìœ„ ì½”ë“œ ì—†ìŒ"]

    result = ["[FLATNESS ë¶„ì„]"]
    top3_codes = code_summary.index.tolist()

    # 3. ê° ì½”ë“œë³„ ìƒì„¸ ë¶„ì„
    for code in top3_codes:
        df_code = df[df['AFT_BAD_RSN_CD'] == code].copy()

        # CUST_SITE_NM, ë“±ê¸‰ ê¸°ì¤€ ì§‘ê³„
        grouped = (
            df_code
            .groupby(['PRODUCT_TYPE', 'GRD_CD_NM_CS', 'GRD_CD_NM_PS'], dropna=False)['LOSS_QTY'] #CUST_SITE_NM
            .sum()
            .reset_index()
        )

        # 30ì¥ ì´ìƒë§Œ í•„í„°
        grouped = grouped[grouped['LOSS_QTY'] >= 30]

        if grouped.empty:
            continue

        # ìˆ˜ëŸ‰ ê¸°ì¤€ ì •ë ¬
        grouped = grouped.sort_values(by='LOSS_QTY', ascending=False).reset_index(drop=True)
        top_row = grouped.iloc[0]  # ìƒìœ„ 1ê°œ

        # ë“±ê¸‰ ì¬ë¶„ë¥˜
        grade_cs = top_row['GRD_CD_NM_CS']
        grade_ps = top_row['GRD_CD_NM_PS']

        if grade_cs == 'Prime' and grade_ps == 'Prime':
            final_grade = 'Prime'
        elif grade_cs == 'Normal' and grade_ps == 'Normal':
            final_grade = 'Normal'
        elif grade_cs == 'Normal' and grade_ps == 'Prime':
            final_grade = 'Premium'
        else:
            final_grade = grade_cs  # ê¸°ë³¸ê°’

        qty = int(top_row['LOSS_QTY'])
        cust = top_row['PRODUCT_TYPE'] if pd.notna(top_row['PRODUCT_TYPE']) else 'Unknown' #CUST_SITE_NM

        result.append(f"- {code} {cust} {final_grade} {qty}ë§¤")

    # ê²°ê³¼ ì—†ì„ ê²½ìš° ì²˜ë¦¬
    if len(result) == 1:
        result.append("ìƒìœ„ 30ì¥ ì´ìƒ ë¶ˆëŸ‰ ì—†ìŒ")

    return result

def analyze_warp(df_wafer):
    """
    Nano Warp ë¶ˆëŸ‰ ë¶„ì„ í†µí•© í•¨ìˆ˜:
    1) ëŒ€ëŸ‰ë¶ˆëŸ‰ (LOSS_QTY â‰¥ 100): ì„¤ë¹„, ë‚ ì§œ í¬í•¨ ë¬¸ì¥ ìƒì„±
    2) ì†ŒëŸ‰ ë°˜ë³µ ë¶ˆëŸ‰ (LOSS_QTY < 100): AFT_BAD_RSN_CD ê¸°ì¤€ ìƒìœ„ 3ê°œ ì¤‘, ê°ê° ìƒìœ„ 3ê°œ BLK_ID ì¶”ì¶œ
    ì…ë ¥: df_wafer (DATA_WAF_3210_wafering_300 ê²°ê³¼)
    """
    df_wafer = df_wafer[df_wafer['REJ_GROUP'] == 'WARP&BOW'].copy()

    if df_wafer.empty:
        return ["[WARP&BOW ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    df_wafer = safe_convert_loss_qty(df_wafer, 'LOSS_QTY')

    result_lines = ["[WARP&BOW ë¶„ì„]"]

    # ë‚ ì§œ í¬ë§· ë³€ê²½: YYYYMMDDHHMMSS â†’ M/D
    def format_date(val):
        try:
            val_str = str(val)
            if len(val_str) >= 8 and val_str[:8].isdigit():
                month = str(int(val_str[4:6]))
                day = str(int(val_str[6:8]))
                return f"{month}/{day}"
            else:
                return "Unknown"
        except:
            return "Unknown"

    df_wafer['REG_DTTM_3200_FMT'] = df_wafer['REG_DTTM_300_WF_3200'].apply(format_date)

    # ê³µí†µ ê·¸ë£¹ ì»¬ëŸ¼
    group_cols = ['AFT_BAD_RSN_CD', 'BLK_ID', 'EQP_NM_300_WF_3200', 'REG_DTTM_3200_FMT']
    grouped = df_wafer.groupby(group_cols, dropna=False)['LOSS_QTY'].sum().reset_index()

    # ëŒ€ëŸ‰ë¶ˆëŸ‰: LOSS_QTY â‰¥ 100
    large_defects = grouped[grouped['LOSS_QTY'] >= 100].copy()
    for _, row in large_defects.iterrows():
        line = f"{row['AFT_BAD_RSN_CD']} {row['BLK_ID']}ì˜ {int(row['LOSS_QTY'])}ë§¤ ({row['EQP_NM_300_WF_3200']} {row['REG_DTTM_3200_FMT']})"
        result_lines.append(line)

    # ì†ŒëŸ‰ ë°˜ë³µ ë¶ˆëŸ‰: LOSS_QTY < 100
    minor_group_cols = ['AFT_BAD_RSN_CD', 'BLK_ID', 'PRODUCT_TYPE', 'GRADE_CS']    # CUST_SITE_NM
    grouped_minor = df_wafer[df_wafer['LOSS_QTY'] < 100].groupby(minor_group_cols, dropna=False)['LOSS_QTY'].sum().reset_index()

    if grouped_minor.empty:
        if len(result_lines) == 1:
            result_lines.append("ëŒ€ëŸ‰/ì†ŒëŸ‰ ë¶ˆëŸ‰ ì—†ìŒ")
        return result_lines

    # AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ
    top3_codes = (
        grouped_minor.groupby('AFT_BAD_RSN_CD')['LOSS_QTY']
        .sum()
        .sort_values(ascending=False)
        .head(3)
        .index.tolist()
    )

    if not top3_codes:
        if len(result_lines) == 1:
            result_lines.append("ì†ŒëŸ‰ ë°˜ë³µ ë¶ˆëŸ‰ ì—†ìŒ")
        return result_lines

    # ê° ìƒìœ„ ì½”ë“œë³„ë¡œ ìƒìœ„ 3ê°œ BLK_ID ì¶”ì¶œ
    for code in top3_codes:
        df_code = grouped_minor[grouped_minor['AFT_BAD_RSN_CD'] == code].copy()
        top3_blks = df_code.nlargest(3, 'LOSS_QTY')

        for _, row in top3_blks.iterrows():
            cust = row['PRODUCT_TYPE'] if pd.notna(row['PRODUCT_TYPE']) else 'Unknown' #PRODUCT_TYPE CUST_SITE_NM
            grade = row['GRADE_CS'] if pd.notna(row['GRADE_CS']) else 'Unknown'
            qty = int(row['LOSS_QTY'])
            line = f"{code} ì—´ìœ„ Lot - {cust} {grade} {row['BLK_ID']} {qty}ë§¤"
            result_lines.append(line)

    if len(result_lines) == 1:
        result_lines.append("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

    return result_lines

def analyze_growing(df_lot):
    """
    GROWING ë¶ˆëŸ‰ ë¶„ì„ í•¨ìˆ˜:
    - AFT_BAD_RSN_CD ê¸°ì¤€ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ
    - ê° ì½”ë“œë³„ IGOT_ID ê¸°ì¤€ LOSS_QTY í•©ê³„ ìƒìœ„ 3ê°œ ì¶”ì¶œ
    ì…ë ¥: df_lot (DATA_LOT_3210_wafering_300 ê²°ê³¼)
    """
    df_lot = df_lot[df_lot['REJ_GROUP'] == 'GROWING'].copy()

    if df_lot.empty:
        return ["[GROWING ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    result_lines = ["[GROWING ë¶„ì„]"]

    # AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ
    code_summary = (
        df_lot.groupby('AFT_BAD_RSN_CD')['LOSS_QTY']
        .sum()
        .sort_values(ascending=False)
        .head(3)
    )

    if code_summary.empty:
        result_lines.append("ìƒìœ„ ë¶ˆëŸ‰ ì½”ë“œ ì—†ìŒ")
        return result_lines

    top3_codes = code_summary.index.tolist()

    # ê° ìƒìœ„ ì½”ë“œë³„ë¡œ IGOT_ID ê¸°ì¤€ ìƒìœ„ 3ê°œ ì¶”ì¶œ
    for code in top3_codes:
        df_code = df_lot[df_lot['AFT_BAD_RSN_CD'] == code].copy()
        grouped = df_code.groupby('IGOT_ID', dropna=False)['LOSS_QTY'].sum().reset_index()
        grouped = grouped.sort_values(by='LOSS_QTY', ascending=False).head(3)

        if grouped.empty:
            continue

        for _, row in grouped.iterrows():
            igot = row['IGOT_ID'] if pd.notna(row['IGOT_ID']) else 'Unknown'
            qty = int(row['LOSS_QTY'])
            line = f"{code} {igot} {qty}ë§¤ íê¸°"
            result_lines.append(line)

    if len(result_lines) == 1:
        result_lines.append("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

    return result_lines

def analyze_broken(df_lot):
    """
    BROKEN ë¶ˆëŸ‰ ë¶„ì„:
    1) AFT_BAD_RSN_CD ê¸°ì¤€ ìƒìœ„ 2ê°œ ì¶”ì¶œ
    2) 'LAP', 'EP', 'FP', 'DSP' í¬í•¨ ì—¬ë¶€ â†’ 'mainê³µì •' / 'ì´ì™¸ê³µì •' ë¶„ë¥˜
    3) ê° ë¶ˆëŸ‰ ì½”ë“œë³„ EQP_ID ê¸°ì¤€ LOSS_QTY ì§‘ê³„ ë° ëª°ë¦¼ì„± íŒë‹¨ (10ë§¤ ì´ìƒ ì°¨ì´ ì‹œ)
    ì…ë ¥: df_lot (DATA_LOT_3210_wafering_300 ê²°ê³¼)
    """
    df_lot = df_lot[df_lot['REJ_GROUP'] == 'BROKEN'].copy()

    if df_lot.empty:
        return ["[BROKEN ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    result = ["[BROKEN ë¶„ì„]"]

    # Step 1: ê³µì •êµ¬ë¶„ - 'LAP', 'EP', 'FP', 'DSP' í¬í•¨ ì—¬ë¶€
    main_keywords = ['LAP', 'EP', 'FP', 'DSP']
    df_lot['ê³µì •êµ¬ë¶„'] = df_lot['AFT_BAD_RSN_CD'].apply(
        lambda x: 'mainê³µì •' if any(k in str(x).upper() for k in main_keywords) else 'ì´ì™¸ê³µì •'
    )

    # Step 2: AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 2ê°œ ì¶”ì¶œ
    top2_codes = (
        df_lot.groupby('AFT_BAD_RSN_CD')['LOSS_QTY']
        .sum()
        .sort_values(ascending=False)
        .head(2)
        .index.tolist()
    )

    if not top2_codes:
        result.append("ìƒìœ„ ë¶ˆëŸ‰ ì½”ë“œ ì—†ìŒ")
        return result

    # Step 3: ê° ìƒìœ„ ì½”ë“œë³„ ë¶„ì„
    for code in top2_codes:
        df_code = df_lot[df_lot['AFT_BAD_RSN_CD'] == code].copy()
        proc_type = df_code['ê³µì •êµ¬ë¶„'].iloc[0] if not df_code.empty else 'Unknown'

        # EQP_ID ê¸°ì¤€ ì§‘ê³„
        grouped = (
            df_code.groupby('EQP_NM', dropna=False)['LOSS_QTY']
            .sum()
            .sort_values(ascending=False)
            .reset_index()
        )

        if grouped.empty:
            result.append(f" - {code} ({proc_type}): ì¥ë¹„ ë°ì´í„° ì—†ìŒ")
            continue

        sub_reason = f"{code} ({proc_type})"

        equip_list = []
        for _, row in grouped.iterrows():
            eqp = row['EQP_NM'] if pd.notna(row['EQP_NM']) else 'Unknown'
            loss = int(row['LOSS_QTY'])
            equip_list.append(f"{eqp}: {loss}ë§¤")
        # íŒë‹¨ ë¬¸êµ¬
        if len(grouped) == 1:
            eqp = grouped.iloc[0]['EQP_NM']
            loss = int(grouped.iloc[0]['LOSS_QTY'])
            eqp_str = eqp if pd.notna(eqp) else 'Unknown'
            final_line = f"{sub_reason} : {eqp_str}: {loss}ë§¤ â†’ {eqp_str} ì¥ë¹„ì— ì™„ì „í•œ ëª°ë¦¼ì„± (1ê°œ ì¥ë¹„)"
            result.append(final_line)
            continue

        # ìƒìœ„ 2ê°œ ì¥ë¹„ ë¹„êµ
        top1 = grouped.iloc[0]
        top2 = grouped.iloc[1]
        diff = int(top1['LOSS_QTY'] - top2['LOSS_QTY'])

        top1_eqp = top1['EQP_NM'] if pd.notna(top1['EQP_NM']) else 'Unknown'
        top2_eqp = top2['EQP_NM'] if pd.notna(top2['EQP_NM']) else 'Unknown'

        details_str = f"{top1_eqp}: {int(top1['LOSS_QTY'])}ë§¤, {top2_eqp}: {int(top2['LOSS_QTY'])}ë§¤"

        if diff >= 10:
            judgment = f" â†’ {top1_eqp} ì¥ë¹„ì— GRë³´ì¦ ì¡´ì¬ ({diff}ë§¤ ì°¨ì´)"
        else:
            judgment = f" â†’ ëª°ë¦¼ì„± íŒë‹¨ ì–´ë ¤ì›€ ({diff}ë§¤ ì°¨ì´)"

        final_line = f"{sub_reason} : {details_str}{judgment}"
        result.append(final_line)

    if len(result) == 1:
        result.append("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

    return result


def analyze_nano(df_wafer):
    """
    NANO ë¶ˆëŸ‰ ë¶„ì„ í†µí•© í•¨ìˆ˜:
    1) ëŒ€ëŸ‰ë¶ˆëŸ‰ (LOSS_QTY â‰¥ 100): ì„¤ë¹„, ë‚ ì§œ í¬í•¨ ë¬¸ì¥ ìƒì„±
    2) ì†ŒëŸ‰ ë°˜ë³µ ë¶ˆëŸ‰ (LOSS_QTY < 100): AFT_BAD_RSN_CD ê¸°ì¤€ ìƒìœ„ 3ê°œ ì¤‘, ê°ê° ìƒìœ„ 3ê°œ BLK_ID ì¶”ì¶œ
    ì…ë ¥: df_wafer (DATA_WAF_3210_wafering_300 ê²°ê³¼)
    """
    df_wafer = df_wafer[df_wafer['REJ_GROUP'] == 'NANO'].copy()

    if df_wafer.empty:
        return ["[NANO ë¶„ì„] ë°ì´í„° ì—†ìŒ"]
    df_wafer = safe_convert_loss_qty(df_wafer, 'LOSS_QTY')

    result_lines = ["[NANO ë¶„ì„]"]

    # ë‚ ì§œ í¬ë§· ë³€ê²½: YYYYMMDDHHMMSS â†’ M/D
    def format_date(val):
        try:
            val_str = str(val)
            if len(val_str) >= 8 and val_str[:8].isdigit():
                month = str(int(val_str[4:6]))
                day = str(int(val_str[6:8]))
                return f"{month}/{day}"
            else:
                return "Unknown"
        except:
            return "Unknown"

    df_wafer['REG_DTTM_3200_FMT'] = df_wafer['REG_DTTM_300_WF_3200'].apply(format_date)

    # ê³µí†µ ê·¸ë£¹ ì»¬ëŸ¼ ì •ì˜
    group_cols = ['AFT_BAD_RSN_CD', 'BLK_ID', 'EQP_NM_300_WF_3200', 'REG_DTTM_3200_FMT']
    grouped = df_wafer.groupby(group_cols, dropna=False)['LOSS_QTY'].sum().reset_index()

    # ëŒ€ëŸ‰ë¶ˆëŸ‰: LOSS_QTY â‰¥ 100
    large_defects = grouped[grouped['LOSS_QTY'] >= 100].copy()
    for _, row in large_defects.iterrows():
        line = f"{row['AFT_BAD_RSN_CD']} {row['BLK_ID']}ì˜ {int(row['LOSS_QTY'])}ë§¤ ({row['EQP_NM_300_WF_3200']} {row['REG_DTTM_3200_FMT']})"
        result_lines.append(line)

    # ì†ŒëŸ‰ ë°˜ë³µ ë¶ˆëŸ‰: LOSS_QTY < 100
    minor_group_cols = ['AFT_BAD_RSN_CD', 'BLK_ID', 'PRODUCT_TYPE', 'GRADE_CS']  #PRODUCT_TYPE CUST_SITE_NM
    grouped_minor = df_wafer[df_wafer['LOSS_QTY'] < 100].groupby(minor_group_cols, dropna=False)['LOSS_QTY'].sum().reset_index()

    if grouped_minor.empty:
        if len(result_lines) == 1:
            result_lines.append("ëŒ€ëŸ‰/ì†ŒëŸ‰ ë¶ˆëŸ‰ ì—†ìŒ")
        return result_lines

    # AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ
    top3_codes = (
        grouped_minor.groupby('AFT_BAD_RSN_CD')['LOSS_QTY']
        .sum()
        .sort_values(ascending=False)
        .head(3)
        .index.tolist()
    )

    if not top3_codes:
        if len(result_lines) == 1:
            result_lines.append("ì†ŒëŸ‰ ë°˜ë³µ ë¶ˆëŸ‰ ì—†ìŒ")
        return result_lines

    # ê° ìƒìœ„ ì½”ë“œë³„ë¡œ ìƒìœ„ 3ê°œ BLK_ID ì¶”ì¶œ
    for code in top3_codes:
        df_code = grouped_minor[grouped_minor['AFT_BAD_RSN_CD'] == code].copy()
        top3_blks = df_code.nlargest(3, 'LOSS_QTY')

        for _, row in top3_blks.iterrows():
            cust = row['PRODUCT_TYPE'] if pd.notna(row['PRODUCT_TYPE']) else 'Unknown' #PRODUCT_TYPE CUST_SITE_NM
            grade = row['GRADE_CS'] if pd.notna(row['GRADE_CS']) else 'Unknown' 
            qty = int(row['LOSS_QTY'])
            line = f"{code} ì—´ìœ„ Lot - {cust} {grade} {row['BLK_ID']} {qty}ë§¤"
            result_lines.append(line)

    if len(result_lines) == 1:
        result_lines.append("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

    return result_lines

def analyze_pit(df_wafer):
    """
    PIT ë¶ˆëŸ‰ ë¶„ì„ í•¨ìˆ˜:
    1) AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ
    2) ê° ì½”ë“œë³„ EQP_NM_3670 ê¸°ì¤€ LOSS_QTY í•©ê³„ ìƒìœ„ 3ê°œ ì¥ë¹„ ì¶”ì¶œ
    3) ë‚ ì§œ í˜•ì‹: REG_DTTM_3670 â†’ M/D ë³€í™˜ (ì˜µì…˜ í¬í•¨)
    ì…ë ¥: df_wafer (DATA_WAF_3210_wafering_300 ê²°ê³¼)
    """
    df_wafer = df_wafer[df_wafer['REJ_GROUP'] == 'PIT'].copy()

    if df_wafer.empty:
        return ["[PIT ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    df_wafer = safe_convert_loss_qty(df_wafer, 'LOSS_QTY')

    result_lines = ["[PIT ë¶„ì„]"]

    # ë‚ ì§œ í¬ë§· ë³€ê²½: YYYYMMDDHHMMSS â†’ M/D
    def format_date(val):
        try:
            val_str = str(val)
            if len(val_str) >= 8 and val_str[:8].isdigit():
                month = str(int(val_str[4:6]))
                day = str(int(val_str[6:8]))
                return f"{month}/{day}"
            else:
                return "Unknown"
        except:
            return "Unknown"

    df_wafer['REG_DTTM_3670_FMT'] = df_wafer['REG_DTTM_300_WF_3670'].apply(format_date)

    # AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ
    top3_codes = (
        df_wafer.groupby('AFT_BAD_RSN_CD')['LOSS_QTY']
        .sum()
        .sort_values(ascending=False)
        .head(3)
        .index.tolist()
    )

    if not top3_codes:
        result_lines.append("ìƒìœ„ ë¶ˆëŸ‰ ì½”ë“œ ì—†ìŒ")
        return result_lines

    # ê° ìƒìœ„ ì½”ë“œë³„ ë¶„ì„
    for code in top3_codes:
        df_code = df_wafer[df_wafer['AFT_BAD_RSN_CD'] == code].copy()

        # EQP_NM_3670 ê¸°ì¤€ ì§‘ê³„
        grouped = (
            df_code.groupby(['EQP_NM_300_WF_3670', 'REG_DTTM_3670_FMT'], dropna=False)['LOSS_QTY']
            .sum()
            .reset_index()
            .sort_values('LOSS_QTY', ascending=False)
            .head(3)  # ìƒìœ„ 3ê°œ ì¥ë¹„ + ë‚ ì§œ ì¡°í•©
        )

        if grouped.empty:
            continue

        # ê²°ê³¼ ì¶”ê°€
        for _, row in grouped.iterrows():
            eqp = row['EQP_NM_300_WF_3670'] if pd.notna(row['EQP_NM_300_WF_3670']) else 'Unknown'
            qty = int(row['LOSS_QTY'])
            date = row['REG_DTTM_3670_FMT']
            line = f"{code} ì—´ìœ„ ì¥ë¹„ - {eqp} {qty}ë§¤ ({date})"
            result_lines.append(line)

    if len(result_lines) == 1:
        result_lines.append("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

    return result_lines


def analyze_scratch(df_wafer):
    """
    SCRATCH ë¶ˆëŸ‰ ë¶„ì„ í•¨ìˆ˜:
    1) AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ
    2) ê° ì½”ë“œë³„ë¡œ EQP_NM_6100 / EQP_NM_3670 ê³µì •ì—ì„œì˜ ìµœë‹¤ ë°œìƒ ì¥ë¹„ ë° ë‚ ì§œ ë¶„ì„
    3) ë™ì¼ ìˆ˜ëŸ‰ì¼ ê²½ìš° ì¥ë¹„ ë³‘ê¸° ì¶œë ¥ (ì˜ˆ: Aì¥ë¹„ M/D / Bì¥ë¹„ M/D)
    ì…ë ¥: df_wafer (DATA_WAF_3210_wafering_300 ê²°ê³¼)
    """
    df_wafer = df_wafer[df_wafer['REJ_GROUP'] == 'SCRATCH'].copy()

    if df_wafer.empty:
        return ["[SCRATCH ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    df_wafer = safe_convert_loss_qty(df_wafer, 'LOSS_QTY')

    result = ["[SCRATCH ë¶„ì„]"]

    # 1. AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 3ê°œ
    summary = (
        df_wafer.groupby('AFT_BAD_RSN_CD', dropna=False)['LOSS_QTY']
        .sum()
        .sort_values(ascending=False)
        .head(3)
        .reset_index()
    )

    if summary.empty:
        result.append("ìƒìœ„ ë¶ˆëŸ‰ ì½”ë“œ ì—†ìŒ")
        return result

    # ë¶„ì„ ëŒ€ìƒ ê³µì • ì •ì˜
    process_list = [
        {'eqp_col': 'EQP_NM_300_WF_6100', 'time_col': 'REG_DTTM_300_WF_6100'},
        {'eqp_col': 'EQP_NM_300_WF_3670', 'time_col': 'REG_DTTM_300_WF_3670'}
    ]

    for _, row in summary.iterrows():
        defect = row['AFT_BAD_RSN_CD']
        loss_qty_total = int(row['LOSS_QTY'])
        top_entries = []  # ê° ê³µì •ë³„ ìµœë‹¤ ë°œìƒ ì •ë³´ ì €ì¥

        # ë‘ ê³µì • ëª¨ë‘ ë¶„ì„
        for proc in process_list:
            eqp_col = proc['eqp_col']
            time_col = proc['time_col']

            # í˜„ì¬ ë¶ˆëŸ‰ ì½”ë“œì— ëŒ€í•´ í•„í„°ë§
            filtered = df_wafer[df_wafer['AFT_BAD_RSN_CD'] == defect].copy()

            # ì¥ë¹„ + ì‹œê°„ ê¸°ì¤€ ì§‘ê³„
            grouped = (
                filtered
                .groupby([eqp_col, time_col], dropna=False)['LOSS_QTY']
                .sum()
                .reset_index()
                .sort_values('LOSS_QTY', ascending=False)
            )

            if not grouped.empty:
                top = grouped.iloc[0]
                eqp_name = top[eqp_col]
                reg_time = str(top[time_col])

                # ì‹œê°„ í¬ë§· ë³€í™˜ (YYYYMMDD â†’ M/D)
                if len(reg_time) >= 8 and reg_time[:8].isdigit():
                    reg_time_fmt = f"{int(reg_time[4:6])}/{int(reg_time[6:8])}"
                else:
                    reg_time_fmt = "Unknown"

                # NaN ì²˜ë¦¬
                eqp_str = eqp_name if pd.notna(eqp_name) else "Unknown"

                top_entries.append({
                    'eqp': eqp_str,
                    'time': reg_time_fmt,
                    'loss_qty': int(top['LOSS_QTY'])
                })

        # ê²°ê³¼ ìƒì„±
        if not top_entries:
            result.append(f"{defect}: {loss_qty_total}ë§¤ (ë°œìƒ ì¥ë¹„ ì •ë³´ ì—†ìŒ)")
        else:
            # LOSS_QTY ê¸°ì¤€ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
            top_entries.sort(key=lambda x: x['loss_qty'], reverse=True)
            max_qty = top_entries[0]['loss_qty']

            # ë™ë¥ ì¸ í•­ëª©ë“¤ ì¶”ì¶œ
            winners = [ent for ent in top_entries if ent['loss_qty'] == max_qty]

            # ì¥ë¹„ ì •ë³´ ë¬¸ìì—´ ìƒì„±
            if len(winners) == 1:
                winner = winners[0]
                result.append(f"{defect}: {loss_qty_total}ë§¤ ({winner['eqp']} {winner['loss_qty']}ë§¤ {winner['time']})")
            else:
                devices = " / ".join([f"{w['eqp']} {w['loss_qty']}ë§¤ {w['time']}" for w in winners])
                result.append(f"{defect}: {loss_qty_total}ë§¤ ({devices})")

    if len(result) == 1:
        result.append("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

    return result

def analyze_edge(df_wafer):
    """
    EDGE ë¶ˆëŸ‰ ë¶„ì„ í•¨ìˆ˜:
    1) EG1ì°¨(3335), EG2ì°¨(3696), EBISì¸¡ì •(7000) ê³µì •ë³„ ì¥ë¹„ ê¸°ì¤€ LOSS_QTY ì§‘ê³„
    2) ê° ê³µì •ë³„ ìƒìœ„ 2ê°œ ì¥ë¹„ ë¹„êµ â†’ 10ë§¤ ì´ìƒ ì°¨ì´ ì‹œ "ëª°ë¦¼ ë°œìƒ" íŒë‹¨
    3) LOSS_QTY íƒ€ì… ë³€í™˜, NaN ì²˜ë¦¬, ì¸ë±ìŠ¤ ì•ˆì „ ì ‘ê·¼ ë³´ì¥
    ì…ë ¥: df_wafer (DATA_WAF_3210_wafering_300 ê²°ê³¼)
    """
    # REJ_GROUP í•„í„°ë§
    df_wafer = df_wafer[df_wafer['REJ_GROUP'] == 'EDGE'].copy()

    if df_wafer.empty:
        return ["[EDGE ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    df_wafer = safe_convert_loss_qty(df_wafer, 'LOSS_QTY')

    result = ["[EDGE ë¶„ì„]"]

    # ê³µì • ì •ë³´ ì •ì˜
    process_info = [
        {'eqp_col': 'EQP_NM_300_WF_3335', 'time_col': 'REG_DTTM_300_WF_3335', 'label': 'EG1ì°¨'},
        {'eqp_col': 'EQP_NM_300_WF_3696', 'time_col': 'REG_DTTM_300_WF_3696', 'label': 'EG2ì°¨'},
        {'eqp_col': 'EQP_NM_300_WF_7000', 'time_col': 'REG_DTTM_300_WF_7000', 'label': 'EBISì¸¡ì •'},
    ]

    for proc in process_info:
        eqp_col = proc['eqp_col']
        time_col = proc['time_col']
        label = proc['label']

        # âœ… ì¥ë¹„ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
        if eqp_col not in df_wafer.columns:
            result.append(f"{label} : ì¥ë¹„ ì»¬ëŸ¼ ì—†ìŒ")
            continue

        # âœ… ì¥ë¹„ëª…ì´ NaNì´ ì•„ë‹Œ ë°ì´í„°ë§Œ í•„í„°ë§
        df_proc = df_wafer[df_wafer[eqp_col].notna()].copy()

        if df_proc.empty:
            result.append(f"{label} : ë°ì´í„° ì—†ìŒ")
            continue

        # âœ… ì¥ë¹„ë³„ LOSS_QTY í•©ê³„
        grouped = (
            df_proc.groupby(eqp_col, dropna=False)['LOSS_QTY']
            .sum()
            .reset_index()
            .sort_values('LOSS_QTY', ascending=False)
            .reset_index(drop=True)
        )

        # âœ… ì¥ë¹„ 1ê°œë§Œ ì¡´ì¬í•  ê²½ìš°
        if len(grouped) == 1:
            eqp = grouped.iloc[0][eqp_col]
            qty = int(grouped.iloc[0]['LOSS_QTY'])
            eqp_str = eqp if pd.notna(eqp) else "Unknown"
            result.append(f"{label} : ë‹¨ì¼ ì¥ë¹„ - {eqp_str} {qty}ë§¤")
            continue

        # âœ… ì¥ë¹„ 2ê°œ ì´ìƒ: ìƒìœ„ 2ê°œ ë¹„êµ
        top1 = grouped.iloc[0]
        top2 = grouped.iloc[1]
        diff = int(top1['LOSS_QTY'] - top2['LOSS_QTY'])

        top1_eqp = top1[eqp_col] if pd.notna(top1[eqp_col]) else "Unknown"
        top2_eqp = top2[eqp_col] if pd.notna(top2[eqp_col]) else "Unknown"

        if diff >= 10:  # âœ… >= 10: ì„ê³„ê°’ í¬í•¨
            result.append(f"{label} : {top1_eqp} ì¥ë¹„ ëª°ë¦¼ ë°œìƒ - {int(top1['LOSS_QTY'])}ë§¤ (2ìœ„ ëŒ€ë¹„ +{diff}ë§¤)")
        else:
            result.append(f"{label} : ëª°ë¦¼ ì—†ìŒ - {top1_eqp} {int(top1['LOSS_QTY'])}ë§¤ / {top2_eqp} {int(top2['LOSS_QTY'])}ë§¤")

    if len(result) == 1:
        result.append("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

    return result

def analyze_chip(df_wafer):
    """
    CHIP ë¶ˆëŸ‰ ë¶„ì„ í•¨ìˆ˜:
    1) AFT_BAD_RSN_CD ê¸°ì¤€ LOSS_QTY í•©ê³„ ìƒìœ„ 1ê°œ ì¶”ì¶œ
    2) ë¶„ì„ ëŒ€ìƒ ë¶ˆëŸ‰ ìœ í˜•ì¸ì§€ í™•ì¸ (defect_mapping ê¸°ì¤€)
    3) í•´ë‹¹ ìœ í˜•ë³„ ì¥ë¹„ ê¸°ì¤€ ìƒìœ„ 1, 2ìœ„ ì¶œë ¥ (ëª°ë¦¼ì„± íŒë‹¨ ì œì™¸)
    ì…ë ¥: df_wafer (DATA_WAF_3210_wafering_300 ê²°ê³¼)
    """
    df_wafer = df_wafer[df_wafer['REJ_GROUP'] == 'CHIP'].copy()

    if df_wafer.empty:
        return ["[CHIP ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    df_wafer = safe_convert_loss_qty(df_wafer, 'LOSS_QTY')

    result = ["[CHIP ë¶„ì„]"]

    # STEP 1: AFT_BAD_RSN_CDë³„ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 1ê°œ
    defect_sums = (
        df_wafer.groupby('AFT_BAD_RSN_CD', dropna=False)['LOSS_QTY']
        .sum()
        .reset_index()
        .sort_values('LOSS_QTY', ascending=False)
        .reset_index(drop=True)
    )

    if defect_sums.empty:
        result.append("ë¶„ì„ ëŒ€ìƒ ë¶ˆëŸ‰ ì—†ìŒ")
        return result

    top_defect = defect_sums.iloc[0]['AFT_BAD_RSN_CD']
    result.append(f"ìµœë‹¤ CHIP ë¶ˆëŸ‰ ìœ í˜•: {top_defect}")

    # STEP 2: ë¶„ì„ ëŒ€ìƒ ë¶ˆëŸ‰ ìœ í˜• ë§¤í•‘
    defect_mapping = {
        'EDGE_CHIP': ['EQP_NM_300_WF_3335', 'REG_DTTM_300_WF_3335', 'EQP_NM_300_WF_3696', 'REG_DTTM_300_WF_3696'],
        'CHIP-LAP': ['EQP_NM_300_WF_3670', 'REG_DTTM_300_WF_3670'],
        'CHIP-EG1AF': ['EQP_NM_300_WF_3335', 'REG_DTTM_300_WF_3335', 'EQP_NM_300_WF_3696', 'REG_DTTM_300_WF_3696'],
        'CHIP-EG1BF': ['EQP_NM_300_WF_3300', 'REG_DTTM_300_WF_3300'],
    }

    if top_defect not in defect_mapping:
        result.append(f"ë¶„ì„ ì œì™¸: '{top_defect}'ëŠ” ë¶„ì„ ëŒ€ìƒ ë¶ˆëŸ‰ ìœ í˜•ì´ ì•„ë‹˜")
        return result

    df_sub = df_wafer[df_wafer['AFT_BAD_RSN_CD'] == top_defect].copy()
    eqp_cols = defect_mapping[top_defect]

    # âœ… CHIP-EG1AF: ì£¼ ì¥ë¹„ ì—†ì„ ì‹œ fallback
    if top_defect == 'CHIP-EG1AF':
        primary_eqp = 'EQP_NM_300_WF_3335'
        if primary_eqp not in df_sub.columns or df_sub[primary_eqp].isna().all():
            eqp_cols = ['EQP_NM_300_WF_3300', 'REG_DTTM_300_WF_3300']
            result.append("â†’ ì£¼ ì¥ë¹„ ì •ë³´ ì—†ì–´ EQP_NM_3300ìœ¼ë¡œ ëŒ€ì²´")

    result.append(f"ì„¸ë¶€ë¶ˆëŸ‰: {top_defect}")

    # STEP 3: ê° ì¥ë¹„ ì»¬ëŸ¼ë³„ ë¶„ì„ (2ê°œì”© ë¬¶ìŒ)
    for i in range(0, len(eqp_cols), 2):
        eqp_col = eqp_cols[i]
        time_col = eqp_cols[i + 1] if i + 1 < len(eqp_cols) else None

        # âœ… ì¥ë¹„ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
        if eqp_col not in df_sub.columns:
            result.append(f"{eqp_col}: ì»¬ëŸ¼ ì—†ìŒ")
            continue

        # âœ… ì¥ë¹„ëª…ì´ NaNì´ ì•„ë‹Œ ë°ì´í„°ë§Œ
        df_eqp = df_sub[df_sub[eqp_col].notna()].copy()
        if df_eqp.empty:
            result.append(f"{eqp_col}: ë°ì´í„° ì—†ìŒ")
            continue

        # âœ… ì¥ë¹„ë³„ LOSS_QTY í•©ê³„
        grouped = (
            df_eqp.groupby(eqp_col, dropna=False)['LOSS_QTY']
            .sum()
            .reset_index()
            .sort_values('LOSS_QTY', ascending=False)
            .reset_index(drop=True)
        )

        result.append(f"{eqp_col} ì¥ë¹„ë³„ ë¶ˆëŸ‰ ìƒìœ„")

        # 1ìœ„
        top1 = grouped.iloc[0]
        top1_eqp = top1[eqp_col] if pd.notna(top1[eqp_col]) else "Unknown"
        result.append(f"1ìœ„: {top1_eqp} ({int(top1['LOSS_QTY'])}ë§¤)")

        # 2ìœ„
        if len(grouped) >= 2:
            top2 = grouped.iloc[1]
            top2_eqp = top2[eqp_col] if pd.notna(top2[eqp_col]) else "Unknown"
            result.append(f"2ìœ„: {top2_eqp} ({int(top2['LOSS_QTY'])}ë§¤)")

    return result


def analyze_others(df_lot, rej_group):
    """
    ê¸°íƒ€ ë¶ˆëŸ‰ ê·¸ë£¹ ê³µí†µ ë¶„ì„ í•¨ìˆ˜
    - REJ_GROUPì— ë”°ë¼ AFT_BAD_RSN_CDë³„ LOSS_QTY í•©ê³„ ìƒìœ„ 1ê°œ ì¶œë ¥
    ì…ë ¥:
        df_lot: ì›ë³¸ ë°ì´í„°
        rej_group: REJ_GROUP ê°’ (ì˜ˆ: 'HUMAN_ERR', 'VISUAL', ...)
        group_label_kr: í•œê¸€ ê·¸ë£¹ëª… (ì˜ˆ: 'ì‚¬ëŒì˜¤ë¥˜', 'ì‹œê°ë¶ˆëŸ‰', ...)
    """
    df_group = df_lot[df_lot['REJ_GROUP'] == rej_group].copy()

    if df_group.empty:
        return [f"[{rej_group} ë¶„ì„] ë°ì´í„° ì—†ìŒ"]

    # AFT_BAD_RSN_CDë³„ í•©ê³„ â†’ ìƒìœ„ 1ê°œ
    defect_summary = (
        df_group.groupby('AFT_BAD_RSN_CD', dropna=False)['LOSS_QTY']
        .sum()
        .reset_index()
        .sort_values('LOSS_QTY', ascending=False)
        .reset_index(drop=True)
    )

    if defect_summary.empty:
        return [f"[{rej_group} ë¶„ì„] ë¶„ì„ ëŒ€ìƒ ì—†ìŒ"]

    top_row = defect_summary.iloc[0]
    code = top_row['AFT_BAD_RSN_CD']
    qty = int(top_row['LOSS_QTY'])
    code_str = code if pd.notna(code) else "Unknown"

    return [f"[{rej_group} ë¶„ì„]", f"{code_str} {qty}ì¥ ë“± ì²˜ë¦¬"]

def analyze_HUMAN_ERR(df_lot):
    return analyze_others(df_lot, 'HUMAN_ERR')

def analyze_VISUAL(df_lot):
    return analyze_others(df_lot, 'VISUAL')

def analyze_NOSALE(df_lot):
    return analyze_others(df_lot, 'NOSALE')

def analyze_OTHER(df_lot):
    return analyze_others(df_lot, 'OTHER')

def analyze_GR(df_lot):  # ì´ë¦„ ìˆ˜ì •: GR â†’ GR_ë³´ì¦
    return analyze_others(df_lot, 'GR_ë³´ì¦')


# 1.Particle ìƒì„¸ë¶„ì„
# 1) ê¸°ë³¸ ë¹„ìœ¨ ë¶„ì„(FS, RESC, HG ë¹„ìœ¨)
def analyze_particle_ratios(df_lot, ref_value=1.8, threshold=0.5):
    """
    FS/RESC/HG ë¶ˆëŸ‰ë¥  ë° ë°˜ì˜ìœ¨ì„ 'IN_QTY ì „ì²´ í•©ê³„'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•˜ë©°,
    RESC ì˜í–¥ ì—¬ë¶€ë„ í•¨ê»˜ íŒë‹¨í•˜ì—¬ ê²°ê³¼ ë¬¸ìì—´ë¡œ ë°˜í™˜.
    """
    denominator_data = df_lot[df_lot['REJ_GROUP'] == 'ë¶„ëª¨']
    total_in_qty = denominator_data['IN_QTY'].sum()

    df = df_lot[df_lot['REJ_GROUP'] == 'PARTICLE'].copy()
    result = []
    base_dt = df['BASE_DT'].iloc[0]

    for cret in ['FS', 'RESC', 'HG']:
        cret_total_loss = 0 #cretë³„ total loss_qty ì €ì¥ìš©
        for grade in ['Prime', 'Normal']:
            # ğŸ”¸ ë¶„ì: í•´ë‹¹ ì¡°ê±´ì˜ LOSS_QTY
            loss_qty = df[
                (df['CRET_CD'] == cret) &
                (df['GRD_CD_NM_CS'] == grade) &
                (df['REJ_GROUP'] == 'PARTICLE')
            ]['LOSS_QTY'].sum()

            cret_total_loss += loss_qty

            rate = (loss_qty / total_in_qty * 100) if total_in_qty != 0 else 0.00
            rate_rounded = round(rate, 2)  # ìŒìˆ˜ë„ ìœ ì§€

            result.append({
                'BASE_DT': base_dt,
                'CRET_CD': cret,
                'GRADE_CS': grade,
                'LOSS_QTY': loss_qty,
                'TOTAL_IN_QTY': total_in_qty,
                'RATE(%)': rate_rounded
            })
    
        # cretë³„ totalí–‰ ì¶”ê°€
        rate_total = (cret_total_loss / total_in_qty * 100)
        rate_total_rounded = round(rate_total, 2)

        result.append({
            'BASE_DT': base_dt,
            'CRET_CD': cret,
            'GRADE_CS': 'Total',
            'LOSS_QTY': cret_total_loss,
            'TOTAL_IN_QTY': total_in_qty,
            'RATE(%)': rate_total_rounded
        })

    df_result = pd.DataFrame(result)

    # ğŸ”¹ RESC Total ì˜í–¥ íŒë‹¨
    resc_total_row = df_result[
        (df_result['CRET_CD'] == 'RESC') & 
        (df_result['GRADE_CS'] == 'Total')
    ]

    if resc_total_row.empty or resc_total_row['RATE(%)'].values[0] == 0.00:
        rc_judgement = "RESC ë°˜ì˜ìœ¨ íŒë‹¨ ë¶ˆê°€"
    else:
        rate = resc_total_row['RATE(%)'].values[0]
        rate_floate = float(rate)
        abs_rate = abs(rate)  # ğŸ”¹ ì ˆëŒ“ê°’ ê¸°ì¤€ íŒë‹¨
        lower_bound = ref_value - threshold
        upper_bound = ref_value + threshold

        if abs_rate < lower_bound:
            rc_judgement = f"R/C ì–‘í’ˆ ê°ì†Œ â†’ ë¶ˆëŸ‰ ë¯¸ë‹¬ ê°€ëŠ¥ì„± (ê¸°ì¤€ ëŒ€ë¹„ -{round(ref_value - rate_floate, 2)}%)"
        elif abs_rate  > upper_bound:
            rc_judgement = f"R/C ì–‘í’ˆ ì¦ê°€ â†’ ë¶ˆëŸ‰ ê³¼ë³´ìƒ ê°€ëŠ¥ì„± (ê¸°ì¤€ ëŒ€ë¹„ +{round(rate_floate - ref_value, 2)}%)"
        else:
            rc_judgement = "R/C ì˜í–¥ ë³€ë™ ì•„ë‹˜ â†’ ë‹¤ë¥¸ ìš”ì¸ íƒìƒ‰ í•„ìš”"

    return df_result, rc_judgement

# 2) particle ìƒì„¸ë¶„ì„
def create_particle_table(df_wafer):
    """
    Particle wafer ë‹¨ìœ„ ë°ì´í„°ì—ì„œ ì£¼ìš” ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ LOSS_QTY í•©ê³„ë¥¼ í”¼ë²— í…Œì´ë¸” í˜•íƒœë¡œ ë³€í™˜
    """
    print(f"df_wafer ì»¬ëŸ¼ ëª©ë¡: {list(df_wafer.columns)}")
    index_cols =['BASE_DT','WAF_ID','WAF_SEQ','DIV_CD','FAC_ID','CRET_CD','PROD_ID','IGOT_ID','BLK_ID','SUBLOT_ID','BEF_BAD_RSN_CD','AFT_BAD_RSN_CD','REJ_GROUP','PRODUCT_TYPE','GRADE_CS','GRADE_PS'] #PRODUCT_TYPE CUST_SITE_NM

    #pivotì€ ì˜ ì•ˆë˜ì„œ, groupbyë¡œ í•´ê²°
    df_wafer = df_wafer[df_wafer['REJ_GROUP'] == 'PARTICLE'].copy()
    df_grouped = df_wafer.groupby(index_cols, dropna=False)['LOSS_QTY'].sum().reset_index()

    #loss_qtyë³„ êµ¬ë¶„
    df_grouped_plus = df_grouped[df_grouped['LOSS_QTY'] > 0].copy() #df_grouped[df_grouped['LOSS_QTY'] == 1].copy() ë¡œ í•˜ë©´ ë°ì´í„° ì¼ë¶€ ì‚¬ë¼ì§. ì›ì¸ì€ ëª¨ë¥´ê² ìŒ.
    df_grouped_minus = df_grouped[df_grouped['LOSS_QTY'] < 0].copy()

    df_grouped_plus['matching'] = (df_grouped_plus['WAF_SEQ'].astype(str) + df_grouped_plus['IGOT_ID'].astype(str) + df_grouped_plus['AFT_BAD_RSN_CD'].astype(str))
    df_grouped_minus['matching'] = (df_grouped_minus['WAF_SEQ'].astype(str) + df_grouped_minus['IGOT_ID'].astype(str) + df_grouped_minus['BEF_BAD_RSN_CD'].astype(str))

    df_grouped_minus['cat'] = 'Good' #loss_qty = -1ì¸ê²½ìš°, cat(êµ¬ë¶„) ì»¬ëŸ¼ì— Goodìœ¼ë¡œ ì…ë ¥
    df_grouped_plus['cat'] = 'NAN' #ìš°ì„  cat(êµ¬ë¶„)ì»¬ëŸ¼ì„ NANìœ¼ë¡œ ì´ˆê¸°í™”

    #ë§¤ì¹­ëœ ê°’ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ 'Good'ìœ¼ë¡œ ì„¤ì •
    df_grouped_plus.loc[df_grouped_plus['matching'].isin(df_grouped_minus['matching']), 'cat'] = 'Good'

    # âœ… [ìˆ˜ì •] \\~ ì œê±° â†’ ë¬¸ìì—´ ì¡°ê±´ ì§ì ‘ ë¹„êµ (ë¬¸ì œ ì—†ì´ ë™ì‘)
    df_nan_particle = df_grouped_plus[df_grouped_plus['cat'] == 'NAN'].copy()  # í•„í„°ë§

    top3_codes = (df_nan_particle.groupby('AFT_BAD_RSN_CD')['LOSS_QTY'].sum().sort_values(ascending=False).head(3).index.tolist()) # AFT_BAD_RSN_CDë³„ LOSS_QTY í•©ê³„ ìƒìœ„ 3ê°œ ì½”ë“œ ì¶”ì¶œ

    #ê²°ê³¼ list ì‘ì„±
    result_descriptions = []

    for code in top3_codes:
        df_code = df_nan_particle[df_nan_particle['AFT_BAD_RSN_CD'] == code]

        #ê·¸ë£¹í™”í•˜ì—¬ LOSS_QTY í•©ê³„ ê³„ì‚°
        grouped = (df_code.groupby(['PRODUCT_TYPE', 'GRADE_CS', 'GRADE_PS'])['LOSS_QTY'].sum().reset_index().sort_values('LOSS_QTY', ascending=False)) #PRODUCT_TYPE CUST_SITE_NM

        #ê°€ì¥ ë§ì€ LOSS_QTYë¥¼ ê¸°ë¡í•œ í•­ëª© ì„ íƒ
        if not grouped.empty:
            top_row = grouped.iloc[0]
            cust = top_row['PRODUCT_TYPE']  #PRODUCT_TYPE CUST_SITE_NM
            grade_cs = top_row['GRADE_CS']
            grade_ps = top_row['GRADE_PS']
            qty = int(top_row['LOSS_QTY']) #ìˆ˜ëŸ‰ì€ ì •ìˆ˜ë¡œ í‘œí˜„

            #grade ì¬ë¶„ë¥˜
            if grade_cs == 'Prime' and grade_ps == 'Prime':
                final_grade = 'Prime'
            elif grade_cs == 'Normal' and grade_ps == 'Normal':
                final_grade = 'Normal'
            elif grade_cs == 'Normal' and grade_ps == 'Prime':
                final_grade = 'Premium'
            else:
                final_grade = grade_cs  

            result_descriptions.append(f"{code} {cust} {final_grade} {qty} ë§¤")

    return result_descriptions

# particleì™„ì„±
def analyze_particle(df_lot, df_wafer):
    result = []
    # 1) RC íŒë‹¨ ë¹„ìœ¨ ë¶„ì„
    df_result, rc_judgement = analyze_particle_ratios(df_lot)

    print(df_result)
    print(rc_judgement)

    # RESC Total ê°’ ì¶”ì¶œ (safe_get ì—†ì´ ì§ì ‘ ì²˜ë¦¬)
    resc_total_row = df_result[
        (df_result['CRET_CD'] == 'RESC') &
        (df_result['GRADE_CS'] == 'Total')
    ]
    if not resc_total_row.empty:
        total_rate = resc_total_row['RATE(%)'].values[0]
    else:
        total_rate = 0.00

    # Prime, Normal ê°œë³„ ì¶”ì¶œ
    prime_row = df_result[
        (df_result['CRET_CD'] == 'RESC') &
        (df_result['GRADE_CS'] == 'Prime')
    ]
    normal_row = df_result[
        (df_result['CRET_CD'] == 'RESC') &
        (df_result['GRADE_CS'] == 'Normal')
    ]

    prime_rate = prime_row['RATE(%)'].values[0] if not prime_row.empty else 0.00
    normal_rate = normal_row['RATE(%)'].values[0] if not normal_row.empty else 0.00

    # ì¶œë ¥ (FS, HGëŠ” ë¶„ì„ë§Œ, ì¶œë ¥ì€ RESCë§Œ)
    result.append("[PARTICLE ë¶„ì„]")
    result.append(
        f"- RESC : Primeë°˜ì˜ìœ¨:{prime_rate:.2f}%, "
        f"Normalë°˜ì˜ìœ¨:{normal_rate:.2f}%, "
        f"P+Në°˜ì˜ìœ¨:{total_rate:.2f}%, "
        f"íŒì •ê²°ê³¼ : {rc_judgement}"
    )

    # 2) RC ì˜í–¥ ì—†ì„ ë•Œë§Œ wafer ìƒì„¸ë¶„ì„
    if rc_judgement == "R/C ì˜í–¥ ë³€ë™ ì•„ë‹˜ â†’ ë‹¤ë¥¸ ìš”ì¸ íƒìƒ‰ í•„ìš”":
        desc = create_particle_table(df_wafer)
        if desc:
            code_part = "ì½”ë“œë³„: " + ", ".join([d.split(' ', 1)[0] + " " + d.split(' ', 1)[1].rsplit(' ', 1)[0] + " ë§¤" for d in desc])
            cust_part = "ì œí’ˆë³„: " + " / ".join([d.replace(' ë§¤', '') for d in desc])
            result.append(f"- {code_part}")
            result.append(f"- {cust_part}")

    return result


def analyze_sample(df_lot):
    """
    SAMPLE ê´€ë ¨ AFT_BAD_RSN_CD ë¶ˆëŸ‰ ìœ í˜• ìƒì„¸ ë¶„ì„
    - MOM_SAMPLE, LOT_SMPL, SMPL, ê¸°íƒ€ ë“± êµ¬ë¶„í•˜ì—¬ ë¡œì§ ì²˜ë¦¬
    - ìƒìœ„ 2ê°œ ì½”ë“œë§Œ ë¶„ì„ (LOSS_QTY ê¸°ì¤€)
    """
    df_lot = df_lot[df_lot['REJ_GROUP'] == 'SAMPLE'].copy()
    result = ["[SAMPLE ë¶„ì„]"]

    if df_lot.empty:
        result.append("SAMPLE ë¶ˆëŸ‰ ë°ì´í„° ì—†ìŒ")
        return result

    # AFT_BAD_RSN_CDë³„ LOSS_QTY í•©ê³„ â†’ ìƒìœ„ 2ê°œ
    defect_sums = (
        df_lot.groupby('AFT_BAD_RSN_CD')['LOSS_QTY']
        .sum()
        .reset_index()
        .sort_values('LOSS_QTY', ascending=False)
        .head(2)
    )

    if defect_sums.empty:
        result.append("ë¶„ì„í•  ë¶ˆëŸ‰ ë°ì´í„° ì—†ìŒ")
        return result

    for _, row in defect_sums.iterrows():
        code = row['AFT_BAD_RSN_CD']
        total_qty = int(row['LOSS_QTY'])
        df_code = df_lot[df_lot['AFT_BAD_RSN_CD'] == code].copy()

        # 1) MON_SAMPLE
        if code == 'MON_SAMPLE':
            grouped = (
                df_code.groupby('OPER_ID')['LOSS_QTY']
                .sum()
                .reset_index()
                .sort_values('LOSS_QTY', ascending=False)
            )
            over20 = grouped[grouped['LOSS_QTY'] >= 20]

            if not over20.empty:
                top_oper = over20.iloc[0]
                result.append(f"{code} ì´ {total_qty}ì¥ ({top_oper['OPER_ID']} ê³µì • {int(top_oper['LOSS_QTY'])}ì¥ ë“± ë°œì·Œ)")
            else:
                result.append(f"{code} {total_qty}ì¥ (20ì¥ ì´ìƒ ê³µì • ì—†ìŒ)")

        # 2) ENGSFT, ENGSCT, ENGSIS â†’ skip
        elif code in ['ENGSFT', 'ENGSCT', 'ENGSIS']:
            continue  # ë³´ê³ ì„œì—ì„œ ì œì™¸ (ì˜ë„ëœ ìŠ¤í‚µ)

        # 3) LOT_SMPL
        elif code == 'LOT_SMPL':
            grouped = (
                df_code.groupby('PRODUCT_TYPE')['LOSS_QTY'] # PRODUCT_TYPE CUST_SITE_NM
                .sum()
                .reset_index()
                .sort_values('LOSS_QTY', ascending=False)
            )
            if not grouped.empty:
                top_site = grouped.iloc[0]
                result.append(f"{code} ì´ {total_qty}ì¥ ({top_site['PRODUCT_TYPE']} {int(top_site['LOSS_QTY'])}ì¥ ë“± ë°œì·Œ)")
            else:
                result.append(f"{code} {total_qty}ì¥")

        # 4) SMPL
        elif code == 'SMPL':
            grouped = (
                df_code.groupby('IGOT_ID')['LOSS_QTY']
                .sum()
                .reset_index()
                .sort_values('LOSS_QTY', ascending=False)
            )
            over20 = grouped[grouped['LOSS_QTY'] >= 20]
            if not over20.empty:
                top_igot = over20.iloc[0]
                result.append(f"SMPL (Growing Engâ€™r Sample) ì´ {total_qty}ì¥, {top_igot['IGOT_ID']} {int(top_igot['LOSS_QTY'])}ì¥ ë“± ë°œì·Œ")
            else:
                result.append(f"SMPL (Growing Engâ€™r Sample) ì´ {total_qty}ì¥ (20ì¥ ì´ìƒ IGOT_ID ì—†ìŒ)")

        # 5) ê·¸ ì™¸ ì½”ë“œ (20ì¥ ì´ìƒì¸ ê²½ìš°ë§Œ ì¶œë ¥)
        else:
            if total_qty >= 20:
                result.append(f"{code} ì´ {total_qty}ì¥")

    return result
